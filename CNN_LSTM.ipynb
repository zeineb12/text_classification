{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "neah7TrtF1xC",
    "outputId": "60b9ba26-5862-48d5-e1e2-dee65fe26520",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y3FdsOdFyVY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Conv1D, Flatten, MaxPooling1D, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ1i_xHVFyVb"
   },
   "outputs": [],
   "source": [
    "def build_model_cnn_lstm(X,\n",
    "                         y,\n",
    "                         vocabulary_size,\n",
    "                         max_length,\n",
    "                         callbacks_list=None,\n",
    "                         Embedding_size=200,\n",
    "                         batch_size=16384,\n",
    "                         validation_split=0.04,\n",
    "                         epochs=100):\n",
    "    \"\"\"\n",
    "    Create the model for a Convolutional Neural Network with a Long Short-Term Memory Network\n",
    "    INPUT:\n",
    "        X : Multidimensional list - The traning features\n",
    "        y : list                  - The traning results\n",
    "        callbacks_list :          - The callback options for the model\n",
    "        Embedding_size            - The size of the embedding\n",
    "        batch_size                - The size of the batch in the neural network\n",
    "        validation_split          - The validation_test split\n",
    "        epochs                    - The number of epochs\n",
    "    OUTPUT:\n",
    "        Returns the model trained and the history of the training\n",
    "    \"\"\"\n",
    "    print('Using Convolutional Neural Network with a Long Short-Term Memory Network')\n",
    "\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(\n",
    "        Embedding(vocabulary_size, Embedding_size, input_length=max_length))\n",
    "    model_conv.add(Dropout(0.2))\n",
    "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(LSTM(Embedding_size))\n",
    "    model_conv.add(Dense(1, activation='sigmoid'))\n",
    "    model_conv.compile(\n",
    "        loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model_conv.summary()\n",
    "\n",
    "    history_conv = model_conv.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "    return model_conv, history_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvrpOfSlFyVd"
   },
   "outputs": [],
   "source": [
    "#train_set = pd.read_pickle(\"./data/tweets.pkl\")\n",
    "train_set = pd.read_pickle(\"/content/drive/My Drive/EPFL/Machine Learning/MA1/tweets.pkl\")\n",
    "# Shuffle the data to mix the positives and negatives\n",
    "train_set = train_set.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "tweets = list(train_set['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fRO7X1AFyVf"
   },
   "outputs": [],
   "source": [
    "# Tokenizing tweets\n",
    "max_length = 32\n",
    "vocabulary_size = 100000\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "sequences = tokenizer.texts_to_sequences(tweets)\n",
    "X = pad_sequences(sequences, maxlen=max_length)\n",
    "y = (train_set['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_i2R1hzxFyVg",
    "outputId": "d28750cc-27d1-4e2c-afbf-a824b87e82dd",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Convolutional Neural Network with a Long Short-Term Memory Network\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 32, 200)           20000000  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 28, 64)            64064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 200)               212000    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 20,276,265\n",
      "Trainable params: 20,276,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 126924 samples, validate on 54397 samples\n",
      "Epoch 1/100\n",
      "126924/126924 [==============================] - 4s 30us/step - loss: 0.6852 - acc: 0.5698 - val_loss: 0.6684 - val_acc: 0.6146\n",
      "Epoch 2/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.6416 - acc: 0.6289 - val_loss: 0.5952 - val_acc: 0.6710\n",
      "Epoch 3/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.5548 - acc: 0.7081 - val_loss: 0.5214 - val_acc: 0.7380\n",
      "Epoch 4/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.4873 - acc: 0.7620 - val_loss: 0.4750 - val_acc: 0.7710\n",
      "Epoch 5/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.4338 - acc: 0.7981 - val_loss: 0.4534 - val_acc: 0.7879\n",
      "Epoch 6/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.3958 - acc: 0.8213 - val_loss: 0.4411 - val_acc: 0.7940\n",
      "Epoch 7/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.3666 - acc: 0.8388 - val_loss: 0.4352 - val_acc: 0.7987\n",
      "Epoch 8/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.3417 - acc: 0.8535 - val_loss: 0.4400 - val_acc: 0.7986\n",
      "Epoch 9/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.3192 - acc: 0.8650 - val_loss: 0.4535 - val_acc: 0.7956\n",
      "Epoch 10/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2991 - acc: 0.8745 - val_loss: 0.4575 - val_acc: 0.7945\n",
      "Epoch 11/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2783 - acc: 0.8848 - val_loss: 0.4837 - val_acc: 0.7906\n",
      "Epoch 12/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2601 - acc: 0.8934 - val_loss: 0.4890 - val_acc: 0.7907\n",
      "Epoch 13/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2453 - acc: 0.8994 - val_loss: 0.5032 - val_acc: 0.7879\n",
      "Epoch 14/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2312 - acc: 0.9053 - val_loss: 0.5291 - val_acc: 0.7863\n",
      "Epoch 15/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2155 - acc: 0.9123 - val_loss: 0.5401 - val_acc: 0.7841\n",
      "Epoch 16/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.2016 - acc: 0.9185 - val_loss: 0.5807 - val_acc: 0.7817\n",
      "Epoch 17/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1983 - acc: 0.9183 - val_loss: 0.5433 - val_acc: 0.7798\n",
      "Epoch 18/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1878 - acc: 0.9244 - val_loss: 0.6068 - val_acc: 0.7800\n",
      "Epoch 19/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1789 - acc: 0.9277 - val_loss: 0.6090 - val_acc: 0.7783\n",
      "Epoch 20/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1658 - acc: 0.9336 - val_loss: 0.6490 - val_acc: 0.7766\n",
      "Epoch 21/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1555 - acc: 0.9375 - val_loss: 0.6675 - val_acc: 0.7748\n",
      "Epoch 22/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1476 - acc: 0.9418 - val_loss: 0.6897 - val_acc: 0.7746\n",
      "Epoch 23/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1396 - acc: 0.9454 - val_loss: 0.7156 - val_acc: 0.7734\n",
      "Epoch 24/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1315 - acc: 0.9483 - val_loss: 0.7314 - val_acc: 0.7710\n",
      "Epoch 25/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1294 - acc: 0.9489 - val_loss: 0.7141 - val_acc: 0.7727\n",
      "Epoch 26/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1206 - acc: 0.9530 - val_loss: 0.7858 - val_acc: 0.7713\n",
      "Epoch 27/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1131 - acc: 0.9565 - val_loss: 0.8056 - val_acc: 0.7688\n",
      "Epoch 28/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1087 - acc: 0.9579 - val_loss: 0.8356 - val_acc: 0.7681\n",
      "Epoch 29/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.1045 - acc: 0.9603 - val_loss: 0.8319 - val_acc: 0.7695\n",
      "Epoch 30/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0984 - acc: 0.9616 - val_loss: 0.8424 - val_acc: 0.7683\n",
      "Epoch 31/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0923 - acc: 0.9653 - val_loss: 0.8968 - val_acc: 0.7685\n",
      "Epoch 32/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0874 - acc: 0.9669 - val_loss: 0.8886 - val_acc: 0.7663\n",
      "Epoch 33/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0844 - acc: 0.9678 - val_loss: 0.9114 - val_acc: 0.7666\n",
      "Epoch 34/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0825 - acc: 0.9694 - val_loss: 0.9136 - val_acc: 0.7677\n",
      "Epoch 35/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0764 - acc: 0.9718 - val_loss: 0.9661 - val_acc: 0.7641\n",
      "Epoch 36/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0729 - acc: 0.9729 - val_loss: 0.9761 - val_acc: 0.7655\n",
      "Epoch 37/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0678 - acc: 0.9749 - val_loss: 0.9999 - val_acc: 0.7654\n",
      "Epoch 38/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0645 - acc: 0.9761 - val_loss: 1.0173 - val_acc: 0.7655\n",
      "Epoch 39/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0612 - acc: 0.9779 - val_loss: 1.0509 - val_acc: 0.7648\n",
      "Epoch 40/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0594 - acc: 0.9782 - val_loss: 1.0658 - val_acc: 0.7647\n",
      "Epoch 41/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0566 - acc: 0.9795 - val_loss: 1.0621 - val_acc: 0.7652\n",
      "Epoch 42/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0543 - acc: 0.9802 - val_loss: 1.0695 - val_acc: 0.7643\n",
      "Epoch 43/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0524 - acc: 0.9810 - val_loss: 1.1313 - val_acc: 0.7634\n",
      "Epoch 44/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0490 - acc: 0.9823 - val_loss: 1.1130 - val_acc: 0.7641\n",
      "Epoch 45/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0470 - acc: 0.9831 - val_loss: 1.1497 - val_acc: 0.7647\n",
      "Epoch 46/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0471 - acc: 0.9829 - val_loss: 1.1745 - val_acc: 0.7607\n",
      "Epoch 47/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0463 - acc: 0.9834 - val_loss: 1.1518 - val_acc: 0.7626\n",
      "Epoch 48/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0441 - acc: 0.9843 - val_loss: 1.1681 - val_acc: 0.7632\n",
      "Epoch 49/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0412 - acc: 0.9854 - val_loss: 1.2004 - val_acc: 0.7625\n",
      "Epoch 50/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0395 - acc: 0.9857 - val_loss: 1.1931 - val_acc: 0.7622\n",
      "Epoch 51/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0374 - acc: 0.9867 - val_loss: 1.2369 - val_acc: 0.7625\n",
      "Epoch 52/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0357 - acc: 0.9875 - val_loss: 1.2463 - val_acc: 0.7628\n",
      "Epoch 53/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0348 - acc: 0.9882 - val_loss: 1.2380 - val_acc: 0.7622\n",
      "Epoch 54/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0340 - acc: 0.9881 - val_loss: 1.2718 - val_acc: 0.7623\n",
      "Epoch 55/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0341 - acc: 0.9880 - val_loss: 1.2633 - val_acc: 0.7625\n",
      "Epoch 56/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0312 - acc: 0.9893 - val_loss: 1.2882 - val_acc: 0.7629\n",
      "Epoch 57/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0292 - acc: 0.9903 - val_loss: 1.3037 - val_acc: 0.7645\n",
      "Epoch 58/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0285 - acc: 0.9901 - val_loss: 1.3169 - val_acc: 0.7628\n",
      "Epoch 59/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0281 - acc: 0.9904 - val_loss: 1.3257 - val_acc: 0.7606\n",
      "Epoch 60/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0276 - acc: 0.9907 - val_loss: 1.3354 - val_acc: 0.7623\n",
      "Epoch 61/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0256 - acc: 0.9914 - val_loss: 1.3652 - val_acc: 0.7615\n",
      "Epoch 62/100\n",
      "126924/126924 [==============================] - 2s 14us/step - loss: 0.0248 - acc: 0.9917 - val_loss: 1.3716 - val_acc: 0.7615\n",
      "Epoch 63/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0242 - acc: 0.9917 - val_loss: 1.3769 - val_acc: 0.7626\n",
      "Epoch 64/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0227 - acc: 0.9924 - val_loss: 1.3769 - val_acc: 0.7630\n",
      "Epoch 65/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0225 - acc: 0.9925 - val_loss: 1.3997 - val_acc: 0.7627\n",
      "Epoch 66/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0223 - acc: 0.9926 - val_loss: 1.4075 - val_acc: 0.7610\n",
      "Epoch 67/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0212 - acc: 0.9931 - val_loss: 1.4285 - val_acc: 0.7615\n",
      "Epoch 68/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0202 - acc: 0.9936 - val_loss: 1.4185 - val_acc: 0.7619\n",
      "Epoch 69/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0198 - acc: 0.9939 - val_loss: 1.4710 - val_acc: 0.7627\n",
      "Epoch 70/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0195 - acc: 0.9938 - val_loss: 1.4369 - val_acc: 0.7623\n",
      "Epoch 71/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0204 - acc: 0.9930 - val_loss: 1.4890 - val_acc: 0.7619\n",
      "Epoch 72/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0207 - acc: 0.9932 - val_loss: 1.4254 - val_acc: 0.7601\n",
      "Epoch 73/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0207 - acc: 0.9929 - val_loss: 1.4737 - val_acc: 0.7615\n",
      "Epoch 74/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0188 - acc: 0.9937 - val_loss: 1.4857 - val_acc: 0.7613\n",
      "Epoch 75/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 1.5519 - val_acc: 0.7604\n",
      "Epoch 76/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 1.5278 - val_acc: 0.7615\n",
      "Epoch 77/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0172 - acc: 0.9945 - val_loss: 1.5493 - val_acc: 0.7625\n",
      "Epoch 78/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 1.5251 - val_acc: 0.7614\n",
      "Epoch 79/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0151 - acc: 0.9953 - val_loss: 1.5442 - val_acc: 0.7615\n",
      "Epoch 80/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0149 - acc: 0.9956 - val_loss: 1.5414 - val_acc: 0.7615\n",
      "Epoch 81/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0142 - acc: 0.9955 - val_loss: 1.5638 - val_acc: 0.7622\n",
      "Epoch 82/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0142 - acc: 0.9956 - val_loss: 1.5566 - val_acc: 0.7615\n",
      "Epoch 83/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0135 - acc: 0.9955 - val_loss: 1.5796 - val_acc: 0.7617\n",
      "Epoch 84/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0131 - acc: 0.9959 - val_loss: 1.5874 - val_acc: 0.7602\n",
      "Epoch 85/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0133 - acc: 0.9958 - val_loss: 1.5705 - val_acc: 0.7614\n",
      "Epoch 86/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 1.5849 - val_acc: 0.7626\n",
      "Epoch 87/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 1.6134 - val_acc: 0.7622\n",
      "Epoch 88/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0118 - acc: 0.9965 - val_loss: 1.6212 - val_acc: 0.7633\n",
      "Epoch 89/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 1.6228 - val_acc: 0.7613\n",
      "Epoch 90/100\n",
      "126924/126924 [==============================] - 2s 14us/step - loss: 0.0112 - acc: 0.9967 - val_loss: 1.6498 - val_acc: 0.7619\n",
      "Epoch 91/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0114 - acc: 0.9965 - val_loss: 1.6356 - val_acc: 0.7623\n",
      "Epoch 92/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 1.6496 - val_acc: 0.7619\n",
      "Epoch 93/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 1.6467 - val_acc: 0.7630\n",
      "Epoch 94/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0108 - acc: 0.9967 - val_loss: 1.6663 - val_acc: 0.7635\n",
      "Epoch 95/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 1.6805 - val_acc: 0.7616\n",
      "Epoch 96/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 1.6660 - val_acc: 0.7615\n",
      "Epoch 97/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 1.6899 - val_acc: 0.7616\n",
      "Epoch 98/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0102 - acc: 0.9968 - val_loss: 1.6716 - val_acc: 0.7638\n",
      "Epoch 99/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0099 - acc: 0.9969 - val_loss: 1.7163 - val_acc: 0.7623\n",
      "Epoch 100/100\n",
      "126924/126924 [==============================] - 2s 13us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 1.6930 - val_acc: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x7f81beff16d8>,\n",
       " <keras.callbacks.History at 0x7f847bb2c9b0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build_model_cnn_lstm(X,y,vocabulary_size,max_length,\n",
    "#                      callbacks_list=[\n",
    "#                          ModelCheckpoint(\n",
    "#                              filepath='CNN_LSTM_best_weights.hdf5',\n",
    "#                              monitor='val_acc',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True,\n",
    "#                              mode='max'),\n",
    "#                          EarlyStopping(\n",
    "#                              monitor='val_acc', patience=3, mode='max')\n",
    "#                      ],\n",
    "#                      Embedding_size=200,batch_size=16384,validation_split=0.3,epochs=100)\n",
    "\n",
    "build_model_cnn_lstm(X,y,vocabulary_size,max_length, Embedding_size=200,batch_size=16384,validation_split=0.3,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VelZOIi-Lvoe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
