{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-9-neural-networks-with-tfidf-vectors-using-d0b4af6be6d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from wordcloud import WordCloud\n",
    "from utils import open_by_tweets\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from utils import create_csv_submission\n",
    "SEED = 15432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_pickle(\"./data/tweets.pkl\")\n",
    "del train_set['tweet_len']\n",
    "\n",
    "\n",
    "x = train_set.tweet\n",
    "y = train_set.label\n",
    "\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)\n",
    "#x_validation_tfidf, x_test, y_validation, y_test = train_test_split(x_test, y_test, test_size=.5, random_state=SEED)\n",
    "\n",
    "\n",
    "tvec = TfidfVectorizer(max_features=70000,ngram_range=(1, 3))\n",
    "x_train_tfidf = tvec.fit_transform(x_train)\n",
    "x_validation_tfidf = tvec.transform(x_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=70000))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "177694/177694 [==============================] - 780s 4ms/step - loss: 0.4128 - accuracy: 0.8057\n",
      "Epoch 2/6\n",
      "177694/177694 [==============================] - 516s 3ms/step - loss: 0.3028 - accuracy: 0.8647\n",
      "Epoch 3/6\n",
      "177694/177694 [==============================] - 539s 3ms/step - loss: 0.2343 - accuracy: 0.8981\n",
      "Epoch 4/6\n",
      "177694/177694 [==============================] - 543s 3ms/step - loss: 0.1726 - accuracy: 0.9279\n",
      "Epoch 5/6\n",
      "177694/177694 [==============================] - 557s 3ms/step - loss: 0.1171 - accuracy: 0.9539\n",
      "Epoch 6/6\n",
      "177694/177694 [==============================] - 562s 3ms/step - loss: 0.0749 - accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27b8c242ef0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_tfidf,y_train, batch_size =  32, epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.read_pickle(\"./data/tweets_test.pkl\")\n",
    "del to_predict['tweet_len']\n",
    "\n",
    "to_predict.index += 1\n",
    "\n",
    "to_predict = to_predict['tweet']\n",
    "to_predict = to_predict.astype(str)\n",
    "\n",
    "to_predict = tvec.transform(to_predict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [1.4980549e-01],\n",
       "       [8.0309367e-01],\n",
       "       ...,\n",
       "       [0.0000000e+00],\n",
       "       [9.2596138e-01],\n",
       "       [2.1368265e-05]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(to_predict)\n",
    "result\n",
    "#it returns values between [0,1] (since sigmoid is used) \n",
    "#result[result < 0.5] = -1 #replace values < 0.5 to -1\n",
    "#result[result >= 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result < 0.5] = -1 #replace values < 0.5 to -1\n",
    "result[result >= 0.5] = 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_csv_submission([x for x in range(1,len(result)+1)],result,\"keras.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
