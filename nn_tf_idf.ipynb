{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-9-neural-networks-with-tfidf-vectors-using-d0b4af6be6d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from wordcloud import WordCloud\n",
    "from utils import open_by_tweets\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from utils import create_csv_submission\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "SEED = 15432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_pickle(\"./data/tweets.pkl\")\n",
    "del train_set['tweet_len']\n",
    "\n",
    "\n",
    "x = train_set.tweet\n",
    "y = train_set.label\n",
    "\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.3, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)\n",
    "#x_validation_tfidf, x_test, y_validation, y_test = train_test_split(x_test, y_test, test_size=.5, random_state=SEED)\n",
    "\n",
    "\n",
    "tvec = TfidfVectorizer(max_features=70000,ngram_range=(1, 3))\n",
    "x_train_tfidf = tvec.fit_transform(x_train)\n",
    "x_validation_tfidf = tvec.transform(x_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tfidf = tvec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=70000))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126924 samples, validate on 27198 samples\n",
      "Epoch 1/6\n",
      "126924/126924 [==============================] - 487s 4ms/step - loss: 0.0318 - accuracy: 0.9862 - val_loss: 1.4460 - val_accuracy: 0.7842\n",
      "Epoch 2/6\n",
      "126924/126924 [==============================] - 485s 4ms/step - loss: 0.0221 - accuracy: 0.9894 - val_loss: 1.6217 - val_accuracy: 0.7801\n",
      "Epoch 3/6\n",
      "126924/126924 [==============================] - 482s 4ms/step - loss: 0.0169 - accuracy: 0.9910 - val_loss: 1.7479 - val_accuracy: 0.7786\n",
      "Epoch 4/6\n",
      "126924/126924 [==============================] - 499s 4ms/step - loss: 0.0138 - accuracy: 0.9917 - val_loss: 1.9356 - val_accuracy: 0.7780\n",
      "Epoch 5/6\n",
      "126924/126924 [==============================] - 504s 4ms/step - loss: 0.0117 - accuracy: 0.9931 - val_loss: 2.0122 - val_accuracy: 0.7753\n",
      "Epoch 6/6\n",
      "126924/126924 [==============================] - 470s 4ms/step - loss: 0.0101 - accuracy: 0.9942 - val_loss: 2.1268 - val_accuracy: 0.7770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d1d6022f28>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_tfidf,y_train, batch_size =  32, epochs = 6, validation_data = (x_validation_tfidf, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39587    0\n",
      "52214    1\n",
      "95622    1\n",
      "21642    0\n",
      "27013    0\n",
      "9285     0\n",
      "94986    0\n",
      "38308    0\n",
      "3282     0\n",
      "69454    0\n",
      "31817    0\n",
      "32170    1\n",
      "88444    0\n",
      "39533    1\n",
      "74261    1\n",
      "33937    0\n",
      "46931    0\n",
      "78202    0\n",
      "52755    1\n",
      "83421    1\n",
      "22259    1\n",
      "24248    0\n",
      "12498    1\n",
      "37493    0\n",
      "49724    1\n",
      "61973    1\n",
      "94947    1\n",
      "88836    1\n",
      "97975    0\n",
      "95520    1\n",
      "        ..\n",
      "24920    1\n",
      "39397    0\n",
      "3929     1\n",
      "76838    0\n",
      "37564    1\n",
      "12329    1\n",
      "41604    0\n",
      "82189    1\n",
      "90559    0\n",
      "49979    0\n",
      "14205    1\n",
      "45794    0\n",
      "59045    0\n",
      "62775    1\n",
      "11159    1\n",
      "39780    0\n",
      "32748    0\n",
      "13576    0\n",
      "71982    0\n",
      "60503    1\n",
      "69369    0\n",
      "32333    1\n",
      "41260    0\n",
      "92174    0\n",
      "90910    1\n",
      "89250    0\n",
      "82590    1\n",
      "68599    0\n",
      "74588    0\n",
      "38639    1\n",
      "Name: label, Length: 27199, dtype: int64\n",
      "Our model's accuracy is 0.777528585609765\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test_tfidf)\n",
    "result[result < 0.5] = 0 #replace values < 0.5 to -1\n",
    "result[result >= 0.5] = 1\n",
    "\n",
    "#create_csv_submission([x for x in range(1,len(result)+1)],result,\"test_s1.csv\")\n",
    "print(f'Our model\\'s accuracy is {metrics.accuracy_score(y_test, result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer().fit(x_train_tfidf)\n",
    "x_train_tfidf_norm = norm.transform(x_train_tfidf)\n",
    "x_validation_tfidf_norm = norm.transform(x_validation_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126924 samples, validate on 27198 samples\n",
      "Epoch 1/6\n",
      "126924/126924 [==============================] - 464s 4ms/step - loss: 0.4305 - accuracy: 0.7962 - val_loss: 0.3963 - val_accuracy: 0.8161\n",
      "Epoch 2/6\n",
      "126924/126924 [==============================] - 490s 4ms/step - loss: 0.2928 - accuracy: 0.8704 - val_loss: 0.4263 - val_accuracy: 0.8112\n",
      "Epoch 3/6\n",
      "126924/126924 [==============================] - 476s 4ms/step - loss: 0.2143 - accuracy: 0.9075 - val_loss: 0.5014 - val_accuracy: 0.8059\n",
      "Epoch 4/6\n",
      "126924/126924 [==============================] - 426s 3ms/step - loss: 0.1508 - accuracy: 0.9389 - val_loss: 0.5982 - val_accuracy: 0.7999\n",
      "Epoch 5/6\n",
      "126924/126924 [==============================] - 419s 3ms/step - loss: 0.0992 - accuracy: 0.9623 - val_loss: 0.7537 - val_accuracy: 0.7946\n",
      "Epoch 6/6\n",
      "126924/126924 [==============================] - 422s 3ms/step - loss: 0.0631 - accuracy: 0.9765 - val_loss: 0.8984 - val_accuracy: 0.7909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d1d58d6f60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, activation='relu', input_dim=70000))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model1.fit(x_train_tfidf_norm,y_train, batch_size =  32, epochs = 6,validation_data = (x_validation_tfidf_norm, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tfidf_norm = norm.transform(x_validation_tfidf)\n",
    "\n",
    "result1 = model1.predict(x_test_tfidf_norm)\n",
    "result1[result1 < 0.5] = 0 #replace values < 0.5 to -1\n",
    "result1[result1 >= 0.5] = 1\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27198, 70000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation_tfidf_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model's accuracy is 0.5046694609897786\n"
     ]
    }
   ],
   "source": [
    "print(f'Our model\\'s accuracy is {metrics.accuracy_score(y_test, result1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126924 samples, validate on 27198 samples\n",
      "Epoch 1/6\n",
      "126924/126924 [==============================] - 386s 3ms/step - loss: 0.4254 - accuracy: 0.7976 - val_loss: 0.3991 - val_accuracy: 0.8154\n",
      "Epoch 2/6\n",
      "126924/126924 [==============================] - 402s 3ms/step - loss: 0.2700 - accuracy: 0.8792 - val_loss: 0.4429 - val_accuracy: 0.8093\n",
      "Epoch 3/6\n",
      "126924/126924 [==============================] - 407s 3ms/step - loss: 0.1470 - accuracy: 0.9368 - val_loss: 0.6426 - val_accuracy: 0.7992\n",
      "Epoch 4/6\n",
      "126924/126924 [==============================] - 409s 3ms/step - loss: 0.0596 - accuracy: 0.9748 - val_loss: 1.0710 - val_accuracy: 0.7931\n",
      "Epoch 5/6\n",
      "126924/126924 [==============================] - 412s 3ms/step - loss: 0.0272 - accuracy: 0.9874 - val_loss: 1.4320 - val_accuracy: 0.7883\n",
      "Epoch 6/6\n",
      "126924/126924 [==============================] - 412s 3ms/step - loss: 0.0168 - accuracy: 0.9912 - val_loss: 1.6524 - val_accuracy: 0.7854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d1d527ecc0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learning rate\n",
    "import keras\n",
    "custom_adam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_testing_2 = Sequential()\n",
    "model_testing_2.add(Dense(64, activation='relu', input_dim=70000))\n",
    "model_testing_2.add(Dense(1, activation='sigmoid'))\n",
    "model_testing_2.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_testing_2.fit(x_train_tfidf,y_train, batch_size =  32, epochs = 6, validation_data = (x_validation_tfidf, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model's accuracy is 0.7847347328945917\n"
     ]
    }
   ],
   "source": [
    "result2 = model_testing_2.predict(x_test_tfidf)\n",
    "result2[result2 < 0.5] = 0 #replace values < 0.5 to -1\n",
    "result2[result2 >= 0.5] = 1\n",
    "\n",
    "#create_csv_submission([x for x in range(1,len(result)+1)],result,\"test_s1.csv\")\n",
    "print(f'Our model\\'s accuracy is {metrics.accuracy_score(y_test, result2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126924 samples, validate on 27198 samples\n",
      "Epoch 1/5\n",
      "126924/126924 [==============================] - 700s 6ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.3976 - val_accuracy: 0.8168\n",
      "Epoch 2/5\n",
      "126924/126924 [==============================] - 708s 6ms/step - loss: 0.2859 - accuracy: 0.8729 - val_loss: 0.4331 - val_accuracy: 0.8081\n",
      "Epoch 3/5\n",
      "126924/126924 [==============================] - 713s 6ms/step - loss: 0.1939 - accuracy: 0.9144 - val_loss: 0.5536 - val_accuracy: 0.8003\n",
      "Epoch 4/5\n",
      "126924/126924 [==============================] - 717s 6ms/step - loss: 0.1171 - accuracy: 0.9502 - val_loss: 0.7628 - val_accuracy: 0.7969\n",
      "Epoch 5/5\n",
      "126924/126924 [==============================] - 722s 6ms/step - loss: 0.0629 - accuracy: 0.9729 - val_loss: 1.0469 - val_accuracy: 0.7944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d1d42fab38>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#increasing number of nodes\n",
    "model_s_2 = Sequential()\n",
    "model_s_2.add(Dense(128, activation='relu', input_dim=70000))\n",
    "model_s_2.add(Dense(1, activation='sigmoid'))\n",
    "model_s_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_s_2.fit(x_train_tfidf,y_train, batch_size =  32, epochs = 5,validation_data = (x_validation_tfidf, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model's accuracy is 0.7924188389279018\n"
     ]
    }
   ],
   "source": [
    "result3 = model_s_2.predict(x_test_tfidf)\n",
    "result3[result3 < 0.45] = 0 #replace values < 0.5 to -1\n",
    "result3[result3 >= 0.45] = 1\n",
    "\n",
    "#create_csv_submission([x for x in range(1,len(result)+1)],result,\"test_s1.csv\")\n",
    "print(f'Our model\\'s accuracy is {metrics.accuracy_score(y_test, result3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27199, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.read_pickle(\"./data/tweets_test.pkl\")\n",
    "del to_predict['tweet_len']\n",
    "\n",
    "to_predict.index += 1\n",
    "\n",
    "to_predict = to_predict['tweet']\n",
    "to_predict = to_predict.astype(str)\n",
    "\n",
    "to_predict = tvec.transform(to_predict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.6459179e-06],\n",
       "       [4.6879411e-02],\n",
       "       [4.6760169e-01],\n",
       "       ...,\n",
       "       [0.0000000e+00],\n",
       "       [9.6147847e-01],\n",
       "       [9.0432167e-04]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(to_predict)\n",
    "result\n",
    "#it returns values between [0,1] (since sigmoid is used) \n",
    "#result[result < 0.5] = -1 #replace values < 0.5 to -1\n",
    "#result[result >= 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result < 0.5] = -1 #replace values < 0.5 to -1\n",
    "result[result >= 0.5] = 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_csv_submission([x for x in range(1,len(result)+1)],result,\"keras2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
